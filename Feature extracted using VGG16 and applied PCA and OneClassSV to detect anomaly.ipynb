{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of using the vgg16 model as a feature extraction model \n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from pickle import dump\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, roc_curve, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(path):\n",
    "    # load an image from file\n",
    "    image = load_img(path, target_size=(224, 224))\n",
    "\n",
    "    # convert the image pixels to a numpy array\n",
    "    image = img_to_array(image)\n",
    "\n",
    "    # reshape data for the model\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "\n",
    "    # prepare the image for the VGG model\n",
    "    image = preprocess_input(image)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train good images\n",
    "train_good = []\n",
    "for p in glob('./bottle/train/good/*'):\n",
    "    train_good.append(prepare_image(p))\n",
    "    \n",
    "# test small broken\n",
    "test_small = []\n",
    "for p in glob('./bottle/test/broken_small/*'):\n",
    "    test_small.append(prepare_image(p))\n",
    "\n",
    "# test large broken\n",
    "test_large = []\n",
    "for p in glob('./bottle/test/broken_large/*'):\n",
    "    test_large.append(prepare_image(p))\n",
    "    \n",
    "# test contamination\n",
    "test_con = []\n",
    "for p in glob('./bottle/test/contamination/*'):\n",
    "    test_con.append(prepare_image(p))\n",
    "    \n",
    "# test good \n",
    "test_good = []\n",
    "for p in glob('./bottle/test/good/*'):\n",
    "    test_good.append(prepare_image(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = VGG16()\n",
    "                 \n",
    "# remove the output layer\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data):\n",
    "    result = []\n",
    "    for i in range(len(data)):\n",
    "        features = model.predict(data[i])\n",
    "        result.append(features[0])\n",
    "    return pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features using VGG16 model\n",
    "df_train = extract_features(train_good)\n",
    "df_test_small = extract_features(test_small)\n",
    "df_test_large = extract_features(test_large)\n",
    "df_test_con = extract_features(test_con)\n",
    "df_test_good = extract_features(test_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensional_reduction_using_PCA(train and reduced)\n",
    "pca = PCA(n_components=100)\n",
    "df_train_reduced = pca.fit_transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduced the dimension of test set as well using trained pca\n",
    "df_test_small_reduced = pca.transform(df_test_small)\n",
    "df_test_large_reduced = pca.transform(df_test_large)\n",
    "df_test_con_reduced = pca.transform(df_test_con)\n",
    "df_test_good_reduced = pca.transform(df_test_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_inverse = pca.inverse_transform(df_train_reduced)\n",
    "df_test_small_inverse = pca.inverse_transform(df_test_small_reduced)\n",
    "df_test_large_inverse = pca.inverse_transform(df_test_large_reduced)\n",
    "df_test_con_inverse = pca.inverse_transform(df_test_con_reduced)\n",
    "df_test_good_inverse = pca.inverse_transform(df_test_good_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.278414532781598"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define threshold value based on training loss\n",
    "train_loss = np.sum((df_train - df_train_inverse) ** 2, axis=1)\n",
    "threshold = np.max(train_loss)*5\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate loss of small broken\n",
    "small_broken_loss = np.sum((df_test_small - df_test_small_inverse) ** 2, axis=1)\n",
    "# prediction based on threshold\n",
    "predict = [1 if val>threshold else 0 for val in small_broken_loss]\n",
    "real = [1]*len(small_broken_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate loss of large broken\n",
    "large_broken_loss = np.sum((df_test_large - df_test_large_inverse) ** 2, axis=1)\n",
    "# prediction based on threshold\n",
    "predict.extend([1 if val>threshold else 0 for val in large_broken_loss])\n",
    "real.extend([1]*len(large_broken_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate loss of contamination\n",
    "cont_loss = np.sum((df_test_con - df_test_con_inverse) ** 2, axis=1)\n",
    "# prediction based on threshold\n",
    "predict.extend([1 if val>threshold else 0 for val in cont_loss])\n",
    "real.extend([1]*len(cont_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate loss of good test image\n",
    "good_test_loss = np.sum((df_test_good - df_test_good_inverse) ** 2, axis=1)\n",
    "# prediction based on threshold\n",
    "predict.extend([1 if val>threshold else 0 for val in good_test_loss])\n",
    "real.extend([0]*len(good_test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(real, predict):\n",
    "    print('Accuracy: ', accuracy_score(real, predict))\n",
    "    print('\\nPrecision: ', precision_score(real, predict))\n",
    "    print('\\nrecall: ', recall_score(real, predict))\n",
    "    print('\\nf1_score: ', f1_score(real, predict))\n",
    "    print('\\nconfusion_matrix:\\n ', pd.DataFrame(confusion_matrix(real, predict), index=[0, 1], columns=[0, 1]))\n",
    "    print('\\nclassification_report:\\n ', classification_report(real, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9759036144578314\n",
      "\n",
      "Precision:  1.0\n",
      "\n",
      "recall:  0.9692307692307692\n",
      "\n",
      "f1_score:  0.9843749999999999\n",
      "\n",
      "confusion_matrix:\n",
      "      0   1\n",
      "0  18   0\n",
      "1   2  63\n",
      "\n",
      "classification_report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        18\n",
      "           1       1.00      0.97      0.98        65\n",
      "\n",
      "    accuracy                           0.98        83\n",
      "   macro avg       0.95      0.98      0.97        83\n",
      "weighted avg       0.98      0.98      0.98        83\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_metrics(predict, real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use OneClassSVM model to train normal data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(nu=0.001)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define and train one class SVM\n",
    "model = OneClassSVM(gamma='scale', kernel='rbf', nu=0.001)\n",
    "model.fit(df_train_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model prediction on test set\n",
    "test_small_result = model.predict(df_test_small_reduced)\n",
    "test_large_result = model.predict(df_test_large_reduced)\n",
    "test_con_result = model.predict(df_test_con_reduced)\n",
    "test_good_result = model.predict(df_test_good_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make real and predict result\n",
    "predict = test_small_result.tolist()+test_large_result.tolist()+test_con_result.tolist()+test_good_result.tolist()\n",
    "real = [-1 for i in range(len(test_small))]+[-1 for i in range(len(test_large))]+[-1 for i in range(len(test_con))]+[1 for i in range(len(test_good))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(real, predict):\n",
    "    print('Accuracy: ', accuracy_score(real, predict))\n",
    "    print('\\nPrecision: ', precision_score(real, predict))\n",
    "    print('\\nrecall: ', recall_score(real, predict))\n",
    "    print('\\nf1_score: ', f1_score(real, predict))\n",
    "    print('\\nconfusion_matrix:\\n ', pd.DataFrame(confusion_matrix(real, predict), index=[-1, 1], columns=[-1, 1]))\n",
    "    print('\\nclassification_report:\\n ', classification_report(real, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.927710843373494\n",
      "\n",
      "Precision:  0.8\n",
      "\n",
      "recall:  0.8888888888888888\n",
      "\n",
      "f1_score:  0.8421052631578948\n",
      "\n",
      "confusion_matrix:\n",
      "      -1   1\n",
      "-1  61   4\n",
      " 1   2  16\n",
      "\n",
      "classification_report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.94      0.95        65\n",
      "           1       0.80      0.89      0.84        18\n",
      "\n",
      "    accuracy                           0.93        83\n",
      "   macro avg       0.88      0.91      0.90        83\n",
      "weighted avg       0.93      0.93      0.93        83\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_metrics(predict, real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test on large features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(nu=0.01)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = OneClassSVM(gamma='scale', kernel='rbf', nu=0.01)\n",
    "model.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model prediction on test set\n",
    "test_small_result = model.predict(df_test_small)\n",
    "test_large_result = model.predict(df_test_large)\n",
    "test_con_result = model.predict(df_test_con)\n",
    "test_good_result = model.predict(df_test_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = test_small_result.tolist()+test_large_result.tolist()+test_con_result.tolist()+test_good_result.tolist()\n",
    "real = [-1 for i in range(len(test_small))]+[-1 for i in range(len(test_large))]+[-1 for i in range(len(test_con))]+[1 for i in range(len(test_good))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8674698795180723\n",
      "\n",
      "Precision:  0.95\n",
      "\n",
      "recall:  0.6551724137931034\n",
      "\n",
      "f1_score:  0.7755102040816326\n",
      "\n",
      "confusion_matrix:\n",
      "      -1   1\n",
      "-1  53   1\n",
      " 1  10  19\n",
      "\n",
      "classification_report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.98      0.91        54\n",
      "           1       0.95      0.66      0.78        29\n",
      "\n",
      "    accuracy                           0.87        83\n",
      "   macro avg       0.90      0.82      0.84        83\n",
      "weighted avg       0.88      0.87      0.86        83\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_metrics(predict, real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.pyimagesearch.com/2019/06/24/change-input-shape-dimensions-for-fine-tuning-with-keras/\n",
    "\n",
    "# https://www.kaggle.com/paperboiii/one-class-classification-for-images\n",
    "\n",
    "# https://www.kaggle.com/trolukovich/food-5k-feature-extraction-with-resnet50-keras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
